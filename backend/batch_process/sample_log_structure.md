# Sample Log File Structure

This document shows the structure of the comprehensive log files generated by the enhanced batch processor.

## üìÅ Log Files Generated

The batch processor now generates three types of log files:

1. **Comprehensive Log** - `batch_processing_log_YYYYMMDD_HHMMSS.json`
2. **Summary Log** - `batch_summary_YYYYMMDD_HHMMSS.json`
3. **Error Log** - `batch_error_log_YYYYMMDD_HHMMSS.json`

## üîç Comprehensive Log Structure

```json
{
  "metadata": {
    "timestamp": "2025-01-15T10:30:00.123456",
    "processor_version": "1.0.0",
    "upload_dir": "uploads",
    "temp_dir": "temp",
    "log_dir": "logs"
  },
  "summary": {
    "stats": {
      "total_files": 150,
      "processed_successfully": 145,
      "skipped_duplicates": 3,
      "failed_files": 2,
      "errors": []
    },
    "total_processing_time": 7200.5,
    "files_processed": 150
  },
  "detailed_log": [
    {
      "timestamp": "2025-01-15T10:30:01.123456",
      "filename": "cv_john_doe.pdf",
      "step": "START",
      "status": "info",
      "details": "Processing started",
      "error": ""
    },
    {
      "timestamp": "2025-01-15T10:30:01.234567",
      "filename": "cv_john_doe.pdf",
      "step": "DUPLICATE_CHECK",
      "status": "info",
      "details": "Checking for duplicates...",
      "error": ""
    },
    {
      "timestamp": "2025-01-15T10:30:01.345678",
      "filename": "cv_john_doe.pdf",
      "step": "DUPLICATE_CHECK",
      "status": "success",
      "details": "No duplicates found",
      "error": ""
    },
    {
      "timestamp": "2025-01-15T10:30:01.456789",
      "filename": "cv_john_doe.pdf",
      "step": "FILE_INFO",
      "status": "info",
      "details": "Type: .pdf, Size: 245.3 KB",
      "error": ""
    },
    {
      "timestamp": "2025-01-15T10:30:01.567890",
      "filename": "cv_john_doe.pdf",
      "step": "FILE_COPY",
      "status": "success",
      "details": "Copied to uploads/abc123_cv_john_doe.pdf",
      "error": ""
    },
    {
      "timestamp": "2025-01-15T10:30:01.678901",
      "filename": "cv_john_doe.pdf",
      "step": "WORKFLOW_PROCESSING",
      "status": "info",
      "details": "Starting workflow processing...",
      "error": ""
    },
    {
      "timestamp": "2025-01-15T10:30:05.123456",
      "filename": "cv_john_doe.pdf",
      "step": "WORKFLOW_PROCESSING",
      "status": "success",
      "details": "Workflow completed successfully",
      "error": ""
    }
  ],
  "configuration": {
    "supported_extensions": [".pdf", ".doc", ".docx", ".rtf", ".txt", ".json", ".jpg", ".jpeg", ".png", ".bmp", ".tiff"],
    "max_file_size_mb": 100,
    "processing_delay_seconds": 0.5
  }
}
```

## üìä Summary Log Structure

```json
{
  "timestamp": "2025-01-15T10:30:00.123456",
  "stats": {
    "total_files": 150,
    "processed_successfully": 145,
    "skipped_duplicates": 3,
    "failed_files": 2,
    "errors": []
  },
  "upload_dir": "uploads",
  "temp_dir": "temp"
}
```

## ‚ùå Error Log Structure

```json
{
  "timestamp": "2025-01-15T10:30:00.123456",
  "total_errors": 2,
  "errors": [
    {
      "filename": "corrupted_cv.pdf",
      "error": "File is corrupted and cannot be processed",
      "timestamp": "2025-01-15T10:35:00.123456",
      "step": "processing"
    },
    {
      "filename": "large_file.pdf",
      "error": "File size exceeds maximum limit (150MB > 100MB)",
      "timestamp": "2025-01-15T10:40:00.123456",
      "step": "processing"
    }
  ]
}
```

## üîç Duplicate Detection Methods

The enhanced processor now uses three methods to detect duplicates:

### 1. **Hash-based Detection** (Most Reliable)
- Calculates SHA-256 hash of file content
- Identifies exact file duplicates regardless of filename
- Method: `check_file_exists_by_hash()`

### 2. **Filename-based Detection** (Case-insensitive)
- Checks if filename already exists in database
- Useful for detecting renamed duplicates
- Method: `check_file_exists_by_filename()`

### 3. **Path-based Detection** (Fallback)
- Uses existing file path checking
- Method: `check_file_exists()`

## üìù Processing Steps Logged

Each file processing is logged with these steps:

1. **START** - Processing begins
2. **DUPLICATE_CHECK** - Checking for duplicates
3. **DUPLICATE_SKIP** - File skipped (if duplicate found)
4. **FILE_INFO** - File information extracted
5. **FILE_COPY** - File copied to upload directory
6. **WORKFLOW_PROCESSING** - Workflow service processing
7. **PROCESSING_ERROR** - Any unexpected errors

## üöÄ Usage Examples

### Basic Processing with Enhanced Logging
```bash
python run_batch_processor.py "C:/CVs"
```

### Custom Log File Names
```bash
python run_batch_processor.py "C:/CVs" --log-file "my_custom_log.json" --error-log "my_errors.json"
```

### Processing with File Type Filter
```bash
python run_batch_processor.py "C:/CVs" --file-types "pdf,docx" --limit 50
```

## üìä Log Analysis

The comprehensive logs can be analyzed to:

- **Track Processing Performance**: Individual file processing times
- **Identify Bottlenecks**: Which steps take longest
- **Monitor Success Rates**: Success/failure statistics
- **Debug Issues**: Detailed error information with context
- **Audit Processing**: Complete audit trail of all operations

## üîß Log Configuration

Log files are automatically saved to the `logs/` directory with:
- **Timestamped filenames** for easy identification
- **UTF-8 encoding** for international character support
- **Pretty-printed JSON** for human readability
- **Automatic directory creation** if logs directory doesn't exist
